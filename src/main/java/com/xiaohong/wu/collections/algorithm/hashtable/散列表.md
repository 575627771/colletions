##散列表

* 散列函数：hash(key)中的hash()就是散列函数；

* 散列值：散列函数计算后得到得值就是散列值；

* 设计要求：

    `1、散列函数计算得到的散列值是一个非负整数`

    `2、如果key1=key2,那么hash(key1)==hash(key2)`

    `3、如果key1=/key2，那么hash(key1) =/ hash(key2)`

* 散列冲突：几乎没有一个完美的无冲突散列函数；即便能找到也要付出其他更多的代价；

  解决办法：
  * 开放寻址法:
    * 线性探测：`冲突过后顺序往后一个一个找，看有没有空位置，如果没有再从表头开始找，
  直到找到空位置；查找的时候也是一样，通过hash函数得到散列值后比较数组中下标为散列值的元素
  和要查找的元素是否相等，相等则返回，否则继续向下查找直到遇见第一个为空位置；
  这时候的删除操作就需要特殊处理不能直接把元素删除，而是将删除的元素特殊标记为deleted
  当查找遇到deleted时继续向下查找;`
    * 二次探测：`线性探测的步长是1，而二次探测的步长是是线性探测的二次方`
    * 双重散列：`即使用一组散列函数，先用第一个散列函数，如果计算得到的存储位置已经被占用
  那么在使用第二个散列函数，依次类推，直到找到空闲位置`
  
  但是不管采用什么探测方法，在散列表空险位置不多的时候，散列冲突的概率就会大大增加，因此
  需要保证散列表中有一定比例的空闲位置，--装载因子
  
  装载因子计算公式：
  
  `散列表装载因子 = 填入表中的元素个数/散列表的长度`
  
  **装载因子越大，说明空闲位置越少，冲突越多，散列表性能会下降**
  
  * 链表法：`每个桶或者槽都会对应一条链表，所有散列值相同的元素都放在相同槽位对应的链表中`
  
  **开放寻址法中的数据都存储在数组中，可以利用cpu缓存加快查询速度，且序列化方便；
  数据量小装载因子小的时候适合采用开放寻址法，如Java中的ThreadLocalMap**
  
  **链表法的内存利用率高，对大装载因子容忍度高，但是由于链表不是连续内存，对cpu缓存不是
  很友好，对执行效率有一定影响，同时链表还需要存储额外的指针，因此内存消耗比开放寻址法大；
  同时还可以继续把链表改成其他高效的数据结构，比如跳表、红黑树等等**

### 散列表和链表为什么经常一起使用

    LRU缓存淘汰策略使用链表+散列表优化，链表使用双向链表，每个散列后的元素都在两条链表中
    类似于使用链表法的散列表，只是多了双向指针，将数据连成一个双向链表，每个散列元素后有
    一个链表，同时所有的元素通过双向指针也可以链接成一个链表；
  -----------------------------
    Redis有序集合（ZSET）同样也是使用散列表来快速定位一个key的位置，然后再后面使用双向
    链表实现的跳表实现快速查找等操作；
  -----------------------------
    LinkedHashMap 按照访问时间排序的时候就是一个LRU缓存淘汰策略缓存系统，其实现原理一摸一样，
    所以这里的linked只的是使用了双向链表。


##哈希算法（散列算法）
  将任意长度的二进制值串映射为固定长度的二进制值串。
* 一般需要满足一下几点
  * 从哈希值不能反向推导出原始数据
  * 对输入数据非常敏感，哪怕是原始数据只修改了一个Bit，最后得到的哈希值也大不相同
  * 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小
  * 哈希算法的执行效率要尽量高效，针对长文本，也能快速的计算出哈希值
  

* 哈希算法的应用
    * 安全加密
        * 最常用的就是MD5算法和SHA安全散列算法
        * 还有DES（数据加密标准）AES（高级加密标准）
        
            两点比较重要：
            * 不能反向推导
            * 散列冲突小
    * 唯一标识
    * 数据校验
    * 散列函数
















